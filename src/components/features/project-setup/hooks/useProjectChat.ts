import { useState, useEffect, useRef } from 'react';
import { invoke } from '@tauri-apps/api/core';
import { Message } from '../../../../types/project-setup';
import { 
    ProjectConfig, 
    Language,
    getProjectSetupSystemPrompt,
    parseProjectConfigFromAI,
    checkProjectCompleteness
} from '../../../../utils/projectConfig';
import { PROVIDER_MODELS } from '../../../../constants/ai-models';

interface UseProjectChatProps {
    projectConfig: ProjectConfig;
    setProjectConfig: React.Dispatch<React.SetStateAction<ProjectConfig>>;
}

export function useProjectChat({ projectConfig, setProjectConfig }: UseProjectChatProps) {
    const [messages, setMessages] = useState<Message[]>([
        { role: 'assistant', content: 'å—¨ï¼æˆ‘æ˜¯ä½ çš„å°ˆæ¡ˆé…ç½®åŠ©æ‰‹ã€‚è«‹å‘Šè¨´æˆ‘ä½ æƒ³åšä»€éº¼æ¨£çš„å°ˆæ¡ˆï¼Ÿ' }
    ]);
    const [isThinking, setIsThinking] = useState(false);
    const [isComposing, setIsComposing] = useState(false);
    
    // AI Settings State
    const [currentProvider, setCurrentProvider] = useState<string>('google');
    const [currentModel, setCurrentModel] = useState<string>('gemini-2.0-flash');
    const [outputLanguage, setOutputLanguage] = useState<Language>('zh-TW');
    const [showAiSettings, setShowAiSettings] = useState(false);
    const [availableProviders, setAvailableProviders] = useState<string[]>(['google', 'openai', 'anthropic', 'ollama']);
    
    // Refs
    const messagesEndRef = useRef<HTMLDivElement>(null);

    // Load AI Settings
    useEffect(() => {
        const loadSettings = async () => {
            try {
                // Load AI provider settings
                const available: string[] = ['ollama', 'custom'];
                for (const p of Object.keys(PROVIDER_MODELS)) {
                    if (p === 'ollama' || p === 'custom') continue;
                    try {
                        // å˜—è©¦å¾ Tauri è®€å–
                        let key: string | null = null;
                        try {
                            key = await invoke<string | null>('get_setting', { key: `ai_api_key_${p}` });
                        } catch {
                            // Tauri ä¸å¯ç”¨ï¼Œå¾ localStorage è®€å–
                        }
                        
                        // Fallback åˆ° localStorage
                        if (!key) {
                            key = localStorage.getItem(`taskrails_api_key_${p}`);
                        }
                        
                        if (key && key.trim().length > 0) {
                            available.push(p);
                        }
                    } catch (e) {
                         // Key not found
                    }
                }
                setAvailableProviders(available);
                
                // å˜—è©¦å¾ Tauri æˆ– localStorage è®€å– provider/model
                let provider: string | null = null;
                let model: string | null = null;
                try {
                    provider = await invoke<string | null>('get_setting', { key: 'ai_provider' });
                    model = await invoke<string | null>('get_setting', { key: 'ai_model' });
                } catch {
                    // Fallback
                }
                if (!provider) provider = localStorage.getItem('taskrails_ai_provider');
                if (!model) model = localStorage.getItem('taskrails_ai_model');
                
                if (provider && available.includes(provider)) {
                    setCurrentProvider(provider);
                    if (model) setCurrentModel(model);
                } else if (available.length > 0) {
                    setCurrentProvider(available[0]);
                    setCurrentModel(PROVIDER_MODELS[available[0]]?.[0] || '');
                }
                
                const savedLang = localStorage.getItem('taskrails_output_language');
                if (savedLang) setOutputLanguage(savedLang as Language);
            } catch (e) {
                console.error('Failed to load settings:', e);
            }
        };
        loadSettings();
    }, []);

    // Save AI Settings on change
    useEffect(() => {
        localStorage.setItem('taskrails_ai_provider', currentProvider);
        localStorage.setItem('taskrails_ai_model', currentModel);
        localStorage.setItem('taskrails_output_language', outputLanguage);
    }, [currentProvider, currentModel, outputLanguage]);

    // Scroll to bottom
    useEffect(() => {
        messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
    }, [messages]);

    const handleSendMessage = async (content: string) => {
        if (!content.trim() || isThinking) return;
        
        const newMessages: Message[] = [...messages, { role: 'user', content }];
        setMessages(newMessages);
        setIsThinking(true);
        
        try {
            // Calculate completeness for context
            const completenessCheck = checkProjectCompleteness(projectConfig);
            
            // Include current config state in context - è®“ AI çŸ¥é“è¦è¿½å•ä»€éº¼
            const configContext = `
## ğŸ“Š ç•¶å‰å°ˆæ¡ˆé…ç½®ç‹€æ…‹

| é …ç›® | ç‹€æ…‹ | å€¼ |
|------|------|-----|
| å°ˆæ¡ˆåç¨± | ${projectConfig.projectName ? 'âœ… å·²è¨­å®š' : 'âŒ æœªè¨­å®š'} | ${projectConfig.projectName || '-'} |
| å°ˆæ¡ˆç›®æ¨™ | ${projectConfig.projectGoal ? 'âœ… å·²è¨­å®š' : 'âŒ æœªè¨­å®š'} | ${projectConfig.projectGoal?.slice(0, 30) || '-'}${projectConfig.projectGoal && projectConfig.projectGoal.length > 30 ? '...' : ''} |
| æŠ€è¡“æ£§ | ${projectConfig.techStack.length > 0 ? 'âœ… å·²è¨­å®š' : 'âŒ æœªè¨­å®š'} | ${projectConfig.techStack.join(', ') || '-'} |
| åŠŸèƒ½æ¸…å–® | ${projectConfig.features.length > 0 ? 'âœ… å·²è¨­å®š' : 'âŒ æœªè¨­å®š'} | ${projectConfig.features.length > 0 ? `${projectConfig.features.length} é …åŠŸèƒ½` : '-'} |

**å®Œæˆåº¦ï¼š${completenessCheck.progress}%**

## âš ï¸ ä½ çš„ä¸‹ä¸€æ­¥è¡Œå‹•

${completenessCheck.missingRequired.length > 0 ? `
**å¿…é ˆè¿½å•ä»¥ä¸‹é …ç›®ï¼š** ${completenessCheck.missingRequired.join('ã€')}

è«‹ç”¨å‹å–„çš„æ–¹å¼è©¢å•ä½¿ç”¨è€…ï¼Œä¾‹å¦‚ï¼š
${completenessCheck.missingRequired.includes('å°ˆæ¡ˆåç¨±') ? '- ã€Œé€™å€‹å°ˆæ¡ˆè¦å«ä»€éº¼åå­—å‘¢ï¼Ÿã€\n' : ''}${completenessCheck.missingRequired.includes('å°ˆæ¡ˆç›®æ¨™') ? '- ã€Œå¯ä»¥è©³ç´°æè¿°ä¸€ä¸‹é€™å€‹å°ˆæ¡ˆçš„ç›®æ¨™å—ï¼Ÿä¾‹å¦‚è¦è§£æ±ºä»€éº¼å•é¡Œï¼Ÿã€\n' : ''}${completenessCheck.missingRequired.includes('æŠ€è¡“æ£§') ? '- ã€Œä½ æœ‰åå¥½çš„æŠ€è¡“æ£§å—ï¼Ÿä¾‹å¦‚å‰ç«¯ç”¨ React é‚„æ˜¯ Vueï¼Ÿå¾Œç«¯ç”¨ä»€éº¼èªè¨€ï¼Ÿã€\n' : ''}${completenessCheck.missingRequired.includes('åŠŸèƒ½æ¸…å–®') ? '- ã€Œå¯ä»¥åˆ—å‡ºå¹¾å€‹æ ¸å¿ƒåŠŸèƒ½å—ï¼Ÿä¾‹å¦‚ä½¿ç”¨è€…è¦èƒ½åšä»€éº¼ï¼Ÿã€\n' : ''}
**é‡è¦ï¼šç•¶ä½¿ç”¨è€…å›ç­”å¾Œï¼Œä¸€å®šè¦ç”¨æ¨™è¨˜èªæ³•è¨˜éŒ„ï¼**
ä¾‹å¦‚ï¼š/å°ˆæ¡ˆåç¨±/*xxx*ã€/æŠ€è¡“æ£§/*React*, *Node.js*
` : `
ğŸ‰ **æ‰€æœ‰å¿…å¡«é …ç›®å·²å®Œæˆï¼**
è«‹ç”Ÿæˆå®Œæ•´çš„ JSON é…ç½®ï¼ŒåŒ…å« agentsã€diagramsã€tasksã€‚
`}
`;
            
            const apiMessages = [
                { role: 'system', content: getProjectSetupSystemPrompt(outputLanguage) + '\n\n' + configContext },
                ...newMessages
            ];
            
            const response = await invoke<string>('execute_ai_chat', { 
                messages: apiMessages,
                overrideProvider: currentProvider,
                overrideModel: currentModel
            });
            
            // Parse AI response for config updates
            const parsedConfig = parseProjectConfigFromAI(response);
            if (Object.keys(parsedConfig).length > 0) {
                setProjectConfig(prev => ({
                    ...prev,
                    ...parsedConfig,
                    techStack: parsedConfig.techStack?.length ? parsedConfig.techStack : prev.techStack,
                    features: parsedConfig.features?.length ? parsedConfig.features : prev.features,
                    generatedAgents: parsedConfig.generatedAgents || prev.generatedAgents,
                    generatedDiagrams: parsedConfig.generatedDiagrams || prev.generatedDiagrams,
                    generatedTasks: parsedConfig.generatedTasks || prev.generatedTasks
                }));
            }
            
            setMessages(msgs => [...msgs, { role: 'assistant', content: response }]);
        } catch (err) {
            setMessages(msgs => [...msgs, { role: 'assistant', content: `âŒ éŒ¯èª¤ï¼š${err}` }]);
        } finally {
            setIsThinking(false);
        }
    };

    return {
        messages,
        setMessages,
        isThinking,
        isComposing, setIsComposing,
        currentProvider, setCurrentProvider,
        currentModel, setCurrentModel,
        outputLanguage, setOutputLanguage,
        showAiSettings, setShowAiSettings,
        availableProviders,
        handleSendMessage,
        messagesEndRef
    };
}
